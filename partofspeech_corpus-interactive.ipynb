{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb348a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch git+https://github.com/martijnvanbeers/transformers@feature/attention-transformers pandas seaborn matplotlib numpy scikit-learn spacy==2.3.7 https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
    "#!wget https://raw.githubusercontent.com/martijnvanbeers/nlp-attribution-notebooks/main/firsthalf.txt\n",
    "#!wget https://raw.githubusercontent.com/martijnvanbeers/nlp-attribution-notebooks/main/valuezeroing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    ")\n",
    "\n",
    "from valuezeroing import calculate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(\"cuda\"))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4da9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pandas.read_csv(\"firsthalf.txt\", sep=\"\\t\", header=None, names=[\"line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pandas.option_context(\"display.max_colwidth\", 200):\n",
    "    display(corpus.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ddc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTokenizer:\n",
    "    def __init__(self, vocab, tokenizer):\n",
    "        self.vocab = vocab\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, text):\n",
    "        result = self._tokenizer._tokenizer.encode(text)\n",
    "        words = []\n",
    "        spaces = []\n",
    "        for wordix,g in itertools.groupby(zip(range(len(result.word_ids[1:-1])), result.word_ids[1:-1]), key=lambda t: t[1]):\n",
    "            g = list(g)\n",
    "            first_token = g[0][0]\n",
    "            last_token = g[-1][0]\n",
    "            start = result.offsets[first_token+1][0]\n",
    "            end = result.offsets[last_token+1][1]\n",
    "            words.append(text[start:end])\n",
    "            if wordix < max(result.word_ids[1:-1]):\n",
    "                # If next start != current end we assume a space in between\n",
    "                next_start, next_end = result.offsets[last_token + 2]\n",
    "                spaces.append(next_start > end)\n",
    "            else:\n",
    "                if end < len(text):\n",
    "                    spaces.append(True)\n",
    "                else:\n",
    "                    spaces.append(False)\n",
    "        return spacy.tokens.Doc(self.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(transformer, output_attentions=True)#, attentions_with_qk=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer)\n",
    "model = AutoModelForMaskedLM.from_pretrained(transformer, config=config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = TransformerTokenizer(nlp.vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poslist = [\"[CLS]\", \"[SEP]\", \"CCONJ\", \"PROPN\", \"PRON\", \"AUX\", \"VERB\", \"ADP\", \"NOUN\", \"SYM\", \"NUM\", \"DET\", \"PUNCT\"]\n",
    "poslist = [\n",
    "    \"SELF\",\n",
    "    \"[CLS]\",\n",
    "    \"[SEP]\",\n",
    "#    \"\",\n",
    "    \"ADJ\",\n",
    "    \"ADP\",\n",
    "    \"ADV\",\n",
    "    \"AUX\",\n",
    "    \"CONJ\",\n",
    "    \"CCONJ\",\n",
    "    \"DET\",\n",
    "    \"INTJ\",\n",
    "    \"NOUN\",\n",
    "    \"NUM\",\n",
    "    \"PART\",\n",
    "    \"PRON\",\n",
    "    \"PROPN\",\n",
    "    \"PUNCT\",\n",
    "    \"SCONJ\",\n",
    "    \"SYM\",\n",
    "    \"VERB\",\n",
    "    \"X\",\n",
    "    \"EOL\",\n",
    "    \"SPACE\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aaf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = None\n",
    "token_count = 0\n",
    "for i, row in corpus.head(10).iterrows():\n",
    "    doc = nlp(row['line'])\n",
    "    scores_matrix, rollout_matrix, att_matrix = calculate_scores(config, model, \"bert\", tokenizer, doc.text)\n",
    "    att_matrix = att_matrix.detach().cpu().numpy()\n",
    "    token_count += scores_matrix.shape[-1]\n",
    "    result = tokenizer(doc.text, return_special_tokens_mask=True, return_offsets_mapping=True)\n",
    "    all_tokens = result.tokens()\n",
    "    docpos = [\"[CLS]\"] + [doc[t].pos_ for t in result.word_ids()[1:-1]] + [\"[SEP]\"]\n",
    "    index = pandas.MultiIndex.from_product(\n",
    "            [numpy.arange(12)+1, numpy.arange(12)+1, all_tokens, all_tokens],\n",
    "            names=['layer','head','from', 'to']\n",
    "        )\n",
    "    score_df = pandas.DataFrame(\n",
    "            numpy.hstack([\n",
    "                    scores_matrix.reshape(-1, 1),\n",
    "                    rollout_matrix.reshape(-1,1),\n",
    "                    att_matrix.reshape(-1,1)\n",
    "                ]),\n",
    "            index=index,\n",
    "            columns=[\"valuezeroing\", \"rollout_vz\", \"raw_attention\"]\n",
    "        ).reset_index()\n",
    "    score_df['from_pos'] = pandas.Categorical(\n",
    "            numpy.tile(numpy.repeat(numpy.array(docpos), len(all_tokens)), 12*12),\n",
    "            categories=poslist\n",
    "        )\n",
    "    score_df['to_pos'] = pandas.Categorical(\n",
    "            numpy.tile(numpy.array(docpos), len(all_tokens)*12*12),\n",
    "            categories=poslist\n",
    "        )\n",
    "    score_df['from_ix'] = numpy.tile(numpy.repeat(numpy.arange(len(all_tokens)), len(all_tokens)), 12*12)\n",
    "    score_df['to_ix'] = numpy.tile(numpy.arange(len(all_tokens)), len(all_tokens)*12*12)\n",
    "    score_df['to_pos'] = score_df.apply(lambda r: \"SELF\" if r['from_ix'] == r['to_ix'] else r['to_pos'], axis=1)\n",
    "    score_df['sent'] = i\n",
    "    counts = ((score_df[(score_df['layer'] == 1) & (score_df['head'] == 1)]\n",
    "                    .groupby([\"from_pos\", \"to_pos\"])\n",
    "                    .agg({\"from\": \"count\"}))\n",
    "                    .rename(columns={'from': 'combo_count'})\n",
    "                    .reset_index()\n",
    "            )\n",
    "    score_df = score_df.merge(counts, how=\"left\", on=[\"from_pos\", \"to_pos\"])\n",
    "    if combined_df is None:\n",
    "        combined_df = score_df\n",
    "    else:\n",
    "        combined_df = pandas.concat([combined_df, score_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bf7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df.iloc[:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pandas.option_context(\"display.max_rows\", None):\n",
    "    display(\n",
    "        combined_df[\n",
    "            (combined_df['layer'] == 1) &\n",
    "            (combined_df['head'] == 1) &\n",
    "            (combined_df['from_pos'] == \"NOUN\") &\n",
    "            (combined_df['to_pos'] == \"ADJ\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\n",
    "        (combined_df['layer'] == 3) &\n",
    "        (combined_df['head'] == 1) &\n",
    "        (combined_df['sent'] == 0) &\n",
    "        (combined_df['from_pos'] == \"ADJ\") &\n",
    "        (combined_df['to_pos'] == \"ADJ\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d449dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (combined_df\n",
    "     .groupby([\"layer\", \"head\", \"from_pos\", \"to_pos\"])\n",
    "     .agg({\n",
    "             \"raw_attention\": lambda n: numpy.sum(n) / token_count,\n",
    "             \"valuezeroing\": lambda n: numpy.sum(n) / token_count,\n",
    "             \"rollout_vz\": lambda n: numpy.sum(n) / token_count,\n",
    "         })\n",
    "     .dropna()\n",
    "     .reset_index())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['adjusted_attention'] = combined_df['raw_attention'] / combined_df['combo_count']\n",
    "combined_df['adjusted_vz'] = combined_df['valuezeroing'] / combined_df['combo_count']\n",
    "combined_df['adjusted_rollout_vz'] = combined_df['rollout_vz'] / combined_df['combo_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = (combined_df\n",
    "     .groupby([\"layer\", \"head\", \"from_pos\", \"to_pos\"])\n",
    "     .agg({\n",
    "         \"adjusted_attention\": lambda n: numpy.sum(n) / token_count,\n",
    "         \"adjusted_vz\": lambda n: numpy.sum(n) / token_count,\n",
    "         \"adjusted_rollout_vz\": lambda n: numpy.sum(n) / token_count,\n",
    "        })\n",
    "     .dropna()\n",
    "     .reset_index())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_head(ignores=[], sortby=\"valuezeroing\", layer=1, head=1, top_n=5):\n",
    "    am = {\n",
    "        'raw_attention': \"adjusted_attention\", \n",
    "        'valuezeroing': \"adjusted_vz\",\n",
    "        'rollout_vz': \"adjusted_rollout_vz\",\n",
    "    }\n",
    "    display(g[~g['from_pos'].isin(ignores) & ~g['to_pos'].isin(ignores) & (g['layer'] == layer) & (g['head'] == head)].sort_values(sortby, ascending=False).head(top_n))\n",
    "    display(ga[~ga['from_pos'].isin(ignores) & ~ga['to_pos'].isin(ignores) & (ga['layer'] == layer) & (ga['head'] == head)].sort_values(am[sortby], ascending=False).head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c0848",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = widgets.interactive(show_head,\n",
    "                ignores=widgets.SelectMultiple(\n",
    "                        options=poslist,\n",
    "                        value=['[CLS]', '[SEP]'],\n",
    "                        description='Ignored POS',\n",
    "                        rows=25,\n",
    "                        disabled=False\n",
    "                    ),\n",
    "                sortby=widgets.RadioButtons(\n",
    "                        options=['raw_attention', 'valuezeroing', 'rollout_vz'],\n",
    "                        value='valuezeroing',\n",
    "                        layout={'width': 'max-content'}, # If the items' names are long\n",
    "                        description='sort by',\n",
    "                    ),\n",
    "                layer=widgets.IntSlider(min=1, max=12, value=1, step=1),\n",
    "                head=widgets.IntSlider(min=1, max=12, value=1, step=1),\n",
    "                top_n=widgets.IntSlider(min=3, max=20, value=10, step=1)\n",
    "            )\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f97fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_combo(from_pos, to_pos, sortby):\n",
    "    with pandas.option_context(\"display.max_rows\", 150):\n",
    "        display(\n",
    "            pandas.concat([\n",
    "                g[(g['from_pos'] == from_pos) & (g['to_pos'] == to_pos)],\n",
    "                ga[(ga['from_pos'] == from_pos) & (ga['to_pos'] == to_pos)][['adjusted_attention', 'adjusted_vz', 'adjusted_rollout_vz']]\n",
    "            ], axis=1).reset_index(drop=True).sort_values(sortby, ascending=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a97a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = widgets.interactive(show_combo,\n",
    "                from_pos=widgets.Select(\n",
    "                        options=poslist,\n",
    "                        value='NOUN',\n",
    "                    ),\n",
    "                to_pos=widgets.Select(\n",
    "                        options=poslist,\n",
    "                        value='NOUN',\n",
    "                    ),\n",
    "                sortby=widgets.RadioButtons(\n",
    "                        options=['raw_attention', 'valuezeroing', 'rollout_vz', 'adjusted_attention', 'adjusted_vz', 'adjusted_rollout_vz'],\n",
    "                        value='valuezeroing',\n",
    "                        layout={'width': 'max-content'}, # If the items' names are long\n",
    "                        description='sort by',\n",
    "                    ),\n",
    "\n",
    "            )\n",
    "display(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
