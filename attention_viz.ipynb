{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title foo\n",
    "!pip install transformers==4.1.1 plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "plotnine.options.figure_size = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer = \"distilbert-base-cased\"\n",
    "transformer = \"bert-base-cased\"\n",
    "#transformer = \"twmkn9/bert-base-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer)\n",
    "model = AutoModel.from_pretrained(transformer, output_attentions=True, output_hidden_states=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"You will either win or lose the game.\",\n",
    "    \"Less is more.\",\n",
    "    \"The quick brown fox jumped over the lazy dog.\",\n",
    "]\n",
    "input_dict = tokenizer(sentences, padding=True, return_tensors=\"pt\")\n",
    "for k, v in input_dict.items():\n",
    "    input_dict[k] = v.to(device)\n",
    "print(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = np.array([a.cpu().detach().numpy() for a in output['attentions']])\n",
    "print(att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort all the attention softmax vectors in descending order\n",
    "sorted = np.take_along_axis(att, (-att).argsort(), axis=-1)\n",
    "print(sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add them up cumulatively\n",
    "cum = sorted.cumsum(axis=-1)\n",
    "print(cum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which ones are below 0.9\n",
    "limit = np.where(cum < 0.9, True, False)\n",
    "print(limit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the ones below 0.9; k is that sum + 1\n",
    "k = limit.sum(axis=-1) + 1\n",
    "print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the 'head' and 'sentence' axes so we can more easily apply the attention mask\n",
    "ks = np.swapaxes(k, 1, 2)\n",
    "print(ks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the attention mask to flag the padding tokens\n",
    "att_mask = input_dict['attention_mask'].cpu().detach()\n",
    "mt = np.ma.MaskedArray(ks, mask = (att_mask == False).expand(ks.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten out the sentences so we're left with just a list of tokens\n",
    "mr = mt.reshape(ks.shape[:2] + tuple([np.prod(ks.shape[2:])]))\n",
    "print(mr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indices of the token list we're interested in\n",
    "unmasked = np.flatnonzero(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dimensions of the data we want\n",
    "# layer X head X #tokens\n",
    "l, h, v = mr[:, :, unmasked].shape\n",
    "print(l, h, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a layer/head multiindex\n",
    "ix = pd.MultiIndex.from_arrays(\n",
    "    [\n",
    "        np.repeat(np.arange(l) + 1,h),\n",
    "        np.tile(np.arange(h) + 1, l)\n",
    "    ], \n",
    "    names=['layer', 'head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally filter out the padding tokens, put the data in a dataframe,\n",
    "# and transform it so we get one layer/head/token/k per row\n",
    "data = (\n",
    "        pd.DataFrame(mr[:,:,unmasked].reshape((l*h,len(unmasked))), index=ix)\n",
    "            .reset_index()\n",
    "            .melt(id_vars=['layer', 'head'])\n",
    "    )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the median k per head\n",
    "avg_k = pd.DataFrame(np.median(mr[:,:,unmasked], axis=-1).flatten(), index=ix, columns=[\"value\"]).reset_index()\n",
    "display(avg_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it!\n",
    "(ggplot(data, aes(1, \"value\"))  + \n",
    "     geom_violin(fill=\"steelblue\") + \n",
    "     geom_jitter(width=0.01, alpha=0.3) +\n",
    "     geom_text(data=avg_k, mapping=aes(x=1, y=5, label=\"value\"), color=\"red\") +\n",
    "     facet_grid(\"layer ~ head\") + \n",
    "     coord_flip()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
