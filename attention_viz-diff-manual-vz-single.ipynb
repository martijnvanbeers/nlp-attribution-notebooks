{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title foo\n",
    "#!pip install transformers==4.1.1 plotnine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting stuff up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import functools\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from IPython.display import HTML\n",
    "import seaborn\n",
    "import matplotlib\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ahviz import create_indices, create_dataframe, filter_mask\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from valuezeroing import calculate_scores_for_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to force CPU if you have a GPU but not enough memory to do what you want. it will be slow of course\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transformer = \"distilbert-base-cased\"\n",
    "#transformer = \"bert-base-cased\"\n",
    "#transformer = \"gpt2\"\n",
    "#transformer = \"gpt2-medium\"\n",
    "#transformer = \"gpt2-large\"\n",
    "#transformer = \"twmkn9/bert-base-uncased-squad2\"\n",
    "family = \"gpt\"\n",
    "transformer = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer)\n",
    "# gpt2 doesn't do padding, so invent a padding token\n",
    "# this one was suggested by the error you get when trying\n",
    "# to do masking below, but it shouldn't matter as the actual\n",
    "# tokens get ignored by the attention mask anyway\n",
    "if family == \"gpt\":\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "config = AutoConfig.from_pretrained(transformer, output_attentions=True)\n",
    "model = AutoModel.from_pretrained(transformer, config=config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation\n",
    "\n",
    "Read in the prepared data. Included in the repository is a copy of the penn treebank sample that is included in the `nltk` python package, converted into plain text and split into sentences. But you can replace this with any\n",
    "text file. Since the first thing we do is join all the text, it isn't even neccessary to split it into sentences.\n",
    "\n",
    "The script I used to create the file is `convert_corpus.py` in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples, prefix=\"sent_\", left=\"more\", right=\"less\"):\n",
    "    if prefix is None:\n",
    "        prefix = \"\"\n",
    "    pleft = f\"{prefix}{left}\"\n",
    "    pright = f\"{prefix}{right}\"\n",
    "        \n",
    "    result = {}\n",
    "    count = len(examples[pleft])\n",
    "    alternating = list(itertools.chain.from_iterable(zip(examples[pleft], examples[pright])))\n",
    "    result = tokenizer(alternating, padding=True)\n",
    "    result['word_ids']  = [result.word_ids(n) for n in range(count*2)]\n",
    "    result['tokens'] = [tokenizer.convert_ids_to_tokens(v) for v in result['input_ids']]\n",
    "    result['token_ix'] = [list(range(len(v))) for v in result['input_ids']]\n",
    "    result['side'] = [left, right] * count\n",
    "    return result\n",
    "encoder = functools.partial(encode, prefix=\"sent_\", left=\"more\", right=\"less\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vz(ds):\n",
    "    df = None\n",
    "    with ds.formatted_as(type='torch', columns=['input_ids', 'attention_mask'], device=\"cuda\"):\n",
    "        dataloader = torch.utils.data.DataLoader(ds, batch_size=4)    \n",
    "        for i, batch_data in enumerate(dataloader):\n",
    "            attention_mask = batch_data['attention_mask'].cpu().numpy()\n",
    "\n",
    "            valuezeroing_scores, rollout_valuezeroing_scores, attentions = calculate_scores_for_batch(\n",
    "                    config,\n",
    "                    model,\n",
    "                    family,\n",
    "                    batch_data['input_ids'],\n",
    "                    batch_data['attention_mask']\n",
    "                )\n",
    "            batch_df = None\n",
    "            for n in numpy.arange(attention_mask.shape[0]):\n",
    "                tok_range = numpy.argwhere(attention_mask[n]).flatten()\n",
    "                f = tok_range.min()\n",
    "                l = tok_range.max() + 1\n",
    "                index = pandas.MultiIndex.from_product(\n",
    "                        [numpy.arange(12)+1, numpy.arange(12)+1, tok_range, tok_range],\n",
    "                        names=['layer','head','from_ix', 'to_ix']\n",
    "                    )\n",
    "                scores_matrix = valuezeroing_scores[:,n,:,f:l, f:l]\n",
    "                att_matrix = attentions.detach().cpu().numpy()[:,n,:,f:l,f:l]\n",
    "                score_df = pandas.DataFrame(\n",
    "                        numpy.hstack([\n",
    "                                scores_matrix.reshape(-1, 1),\n",
    "                                att_matrix.reshape(-1,1)\n",
    "                            ]),\n",
    "                        index=index,\n",
    "                        columns=[\"raw_vz\", \"raw_attention\"]\n",
    "                    ).reset_index()\n",
    "                score_df['example'] = i*2 + n//2\n",
    "                score_df['side'] = \"less\" if n%2 else \"more\"\n",
    "                if batch_df is None:\n",
    "                    batch_df = score_df\n",
    "                else:\n",
    "                    batch_df = pandas.concat([batch_df, score_df])\n",
    "            if df is None:\n",
    "                df = batch_df\n",
    "            else:\n",
    "                df = pandas.concat([df, batch_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(encoded_df, result_df):\n",
    "    left_merge = (encoded_df\n",
    "            .dropna()[['side', 'example', 'token_ix', 'tokens', 'word_ids']]\n",
    "            .rename(columns={\n",
    "                    'token_ix': \"from_ix\",\n",
    "                    'tokens': \"from_token\",\n",
    "                    'word_ids': \"from_word_id\",\n",
    "                })\n",
    "        )\n",
    "    right_merge = (encoded_df\n",
    "            .dropna()[['side', 'example', 'token_ix', 'tokens', 'word_ids']]\n",
    "            .rename(columns={\n",
    "                    'token_ix': \"to_ix\",\n",
    "                    'tokens': \"to_token\",\n",
    "                    'word_ids': \"to_word_id\",\n",
    "                })\n",
    "        )\n",
    "\n",
    "    complete = result_df.merge(left_merge, how=\"left\", on=[\"example\", \"side\", \"from_ix\"])\n",
    "    complete = complete.merge(right_merge, how=\"left\", on=[\"example\", \"side\", \"to_ix\"])\n",
    "    return complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(more=\"foo\", less=\"foo\"):\n",
    "    manual_data = dict(\n",
    "            sent_more = [more],\n",
    "            sent_less = [less],\n",
    "            stereo_antistereo = ['stereo'],\n",
    "            bias_type = ['gender']\n",
    "        )\n",
    "    manual_dataset = datasets.Dataset.from_dict(manual_data)\n",
    "    encoded_dataset = manual_dataset.map(encoder, batched=True, remove_columns=['sent_more', 'sent_less', 'stereo_antistereo', 'bias_type'])\n",
    "\n",
    "    encoded_df = encoded_dataset.to_pandas().explode(['input_ids', 'attention_mask', 'word_ids', 'token_ix', 'tokens']).reset_index(names=\"example\")\n",
    "    encoded_df['example'] //= 2\n",
    "\n",
    "    result_df = run_vz(encoded_dataset)\n",
    "    complete = merge(encoded_df, result_df)\n",
    "    \n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_diff(axes, val_type=\"raw_vz\", complete=None, target=0,source=12):\n",
    "    example=0\n",
    "    c = complete[(complete['example'] == example) & (complete['from_ix'] == source) & (complete['to_ix'] <= complete['from_ix'])]\n",
    "    mr = c[c['side'] == \"more\"]\n",
    "    lr = c[c['side'] == \"less\"]\n",
    "    diff = (lr.set_index(['layer', 'head', 'to_ix'])[['raw_vz']] - mr.set_index(['layer', 'head', 'to_ix'])[['raw_vz']]).reset_index().rename(columns={'raw_vz': \"diff\"})\n",
    "    seaborn.heatmap(\n",
    "            ax=axes[0],\n",
    "            data=c[(c['side'] == 'more') & (c['to_ix'] == target)].pivot(index='layer', columns='head', values=val_type),\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            cmap=seaborn.light_palette(\"seagreen\", as_cmap=True)\n",
    "        )\n",
    "    axes[0].set_title(f\"{mr[(mr['layer'] == 1) & (mr['head'] == 1) & (mr['from_ix'] == source)].reset_index().at[0, 'from_token']} (more stereotypical)\")\n",
    "\n",
    "    seaborn.heatmap(\n",
    "            ax=axes[1],\n",
    "            data=diff[diff['to_ix'] == target].pivot(index='layer', columns='head', values='diff'),\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            #annot=True,\n",
    "            cmap=seaborn.color_palette(\"coolwarm\", as_cmap=True)\n",
    "        )\n",
    "    axes[1].set_title(\"difference\")\n",
    "    axes[1].set_title(mr[(mr['layer'] == 1) & (mr['head'] == 1) & (mr['to_ix'] == target)].reset_index().at[0, 'to_token'], loc='left')\n",
    "    axes[1].set_title(lr[(lr['layer'] == 1) & (lr['head'] == 1) & (lr['to_ix'] == target)].reset_index().at[0, 'to_token'], loc='right')\n",
    "\n",
    "    seaborn.heatmap(\n",
    "            ax=axes[2],\n",
    "            data=c[(c['side'] == 'less') & (c['to_ix'] == target)].pivot(index='layer', columns='head', values=val_type),\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            cmap=seaborn.light_palette(\"seagreen\", as_cmap=True)\n",
    "        )\n",
    "    axes[2].set_title(f\"{lr[(lr['layer'] == 1) & (lr['head'] == 1) & (lr['from_ix'] == source)].reset_index().at[0, 'from_token']} (less stereotypical)\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.invert_yaxis()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8ee7707b74464a96cf69c2df415bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description=\"'left' sentence\", layout=Layout(width='100%'), placeholder='fill me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cbb97faf304dc2b55c76c924040790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description=\"'right' sentence\", layout=Layout(width='100%'), placeholder='fill me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b04e2f82f644fc584a18ed68067729d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process Sentences', style=ButtonStyle(), tooltip='Click me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921747e4314448d78d833f5ced151262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='900px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "more_widget=widgets.Text(\n",
    "        layout={'width': '100%'},\n",
    "        description=\"'left' sentence\",\n",
    "        placeholder=\"fill me\",\n",
    "        disabled=False,\n",
    "    )\n",
    "less_widget=widgets.Text(\n",
    "        layout={'width': '100%'},    \n",
    "        description=\"'right' sentence\",\n",
    "        placeholder=\"fill me\",\n",
    "        disabled=False,\n",
    "    )\n",
    "output = widgets.Output(\n",
    "        layout={'height': '900px'}\n",
    "    )\n",
    "run_button = widgets.Button(\n",
    "        description='Process Sentences',\n",
    "        disabled=False,\n",
    "        button_style='',\n",
    "        tooltip='Click me',\n",
    "    )\n",
    "\n",
    "@output.capture(clear_output=True, wait=True)\n",
    "def on_button_clicked(b):\n",
    "    complete = build_data(more=more_widget.value, less=less_widget.value)\n",
    "    source_widget=widgets.IntSlider(\n",
    "        value=12,\n",
    "        min=0,\n",
    "        max=17,\n",
    "        step=1,\n",
    "        description='source token:',\n",
    "        continuous_update=False,\n",
    "    )\n",
    "    target_widget=widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='target token:',\n",
    "        continuous_update=False,\n",
    "    )\n",
    "    value_widget=widgets.RadioButtons(\n",
    "        options=['raw_attention', 'raw_vz'],\n",
    "        value='raw_vz',\n",
    "        layout={'width': 'max-content'}, # If the items' names are long\n",
    "        description='what to display',\n",
    "    )\n",
    "    nested = widgets.Output()\n",
    "    fig, axes = matplotlib.pyplot.subplots(1, 3, figsize=(16, 6), sharey=True)    \n",
    "    fig.suptitle(\" \".join(list(itertools.takewhile(lambda v: v, [m if m == l else None for m, l in zip(complete[(complete['example'] == example) & (complete['side'] == \"more\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'], complete[(complete['example'] == example) & (complete['side'] == \"less\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'])])) + [\"[...]\"] + list(reversed(list(itertools.takewhile(lambda v: v, [m if m == l else None for m, l in zip(complete[(complete['example'] == example) & (complete['side'] == \"more\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'][::-1], complete[(complete['example'] == example) & (complete['side'] == \"less\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'][::-1])]))))))\n",
    "\n",
    "    @nested.capture(clear_output=True, wait=True)\n",
    "    def on_input_update(*args):\n",
    "        matplotlib.pyplot.close()\n",
    "        fig, axes = matplotlib.pyplot.subplots(1, 3, figsize=(16, 6), sharey=True)    \n",
    "        show_diff(axes, complete=complete,target=target_widget.value,source=source_widget.value,val_type=value_widget.value)\n",
    "        fig.suptitle(\" \".join(list(itertools.takewhile(lambda v: v, [m if m == l else None for m, l in zip(complete[(complete['example'] == example) & (complete['side'] == \"more\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'], complete[(complete['example'] == example) & (complete['side'] == \"less\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'])])) + [\"[...]\"] + list(reversed(list(itertools.takewhile(lambda v: v, [m if m == l else None for m, l in zip(complete[(complete['example'] == example) & (complete['side'] == \"more\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'][::-1], complete[(complete['example'] == example) & (complete['side'] == \"less\") & (complete['layer'] == 1) & (complete['head'] == 1) & (complete['to_ix'] == 0)]['from_token'][::-1])]))))))\n",
    "        with nested:\n",
    "            display(fig)\n",
    "        \n",
    "    @nested.capture(clear_output=True, wait=True)\n",
    "    def on_source_update(*args):\n",
    "        target_widget.max = source_widget.value\n",
    "    \n",
    "    source_widget.observe(on_source_update, 'value')\n",
    "    source_widget.observe(on_input_update, 'value')\n",
    "    target_widget.observe(on_input_update, 'value')\n",
    "    value_widget.observe(on_input_update, 'value')\n",
    "\n",
    "    show_diff(axes, complete=complete,target=target_widget.value,source=source_widget.value,val_type=value_widget.value)\n",
    "    \n",
    "    display(source_widget,target_widget,value_widget, nested)\n",
    "    with nested:\n",
    "        display(fig)\n",
    "\n",
    "run_button.on_click(on_button_clicked)\n",
    "\n",
    "\n",
    "display(more_widget, less_widget, run_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
